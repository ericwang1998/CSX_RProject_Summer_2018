knitr::opts_chunk$set(echo = TRUE)
plot(pressure)
summary(cars)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
library(marmap)
knitr::opts_chunk$set(echo = TRUE)
library(marmap)
install.packages(marmap)
library(knitr)
kable(mtcars[1:5,], caption = "A knitr kable")
knitr::opts_chunk$set(echo = TRUE)
squad_a = 9 + 1 + 1
print(squad_a)
squad_a = 9 + 1 + 1
squad_b = 7 + 1 + 1
squad_c = 7 + 1
platoon_a = squad_a + squad_b + squad_c
print(platoon_a)
sergeant_b_name = "Jackie Wu"
sergeant_b_present = FALSE
print(typeof(sergeant_b_name))
print(typeof(sergeant_b_present))
print(typeof(squad_b))
sergeant_b_name = "Jackie Wu"
sergeant_b_present = FALSE
print(typeof(sergeant_b_name))
print(typeof(sergeant_b_present))
print(typeof(28))
sergeant_b_name = "Jackie Wu"
sergeant_b_present = FALSE
print(typeof(sergeant_b_name))
print(typeof(sergeant_b_present))
print(typeof(squad_b))
sergeant_b_name = "Jackie Wu"
sergeant_b_present = FALSE
print(class(sergeant_b_name))
print(classf(sergeant_b_present))
sergeant_b_name = "Jackie Wu"
sergeant_b_present = FALSE
print(class(sergeant_b_name))
print(class(sergeant_b_present))
print(class(squad_b))
evil_soldiers <- c(22.5, 123.9, 44.8)
just_soldiers <- c(30.7, 60.3, 20.1)
excess_or_lack <- evil_soldiers - just_soldiers
print(excess_or_lack)
evil_soldiers <- c(22.5, 123.9, 44.8)
just_soldiers <- c(30.7, 60.3, 20.1)
excess_or_lack <- just_soldiers - evil_soldiers
print(excess_or_lack)
army_types <- c("Navy", "Land", "Air")
names(excess_or_lack) <- army_types
print(excess_or_lack)
evil_soldiers <- c(44.8, 123.9, 22.5)
just_soldiers <- c(30.7, 60.3, 9.1)
excess_or_lack <- just_soldiers - evil_soldiers
print(excess_or_lack)
evil_soldiers <- c(29.8, 123.9, 18.5)
just_soldiers <- c(30.7, 60.3, 9.1)
excess_or_lack <- just_soldiers - evil_soldiers
print(excess_or_lack)
evil_soldiers <- c(23.8, 123.9, 17.5)
just_soldiers <- c(30.7, 60.3, 9.1)
excess_or_lack <- just_soldiers - evil_soldiers
print(excess_or_lack)
evil_soldiers <- c(25.8, 123.9, 17.5)
just_soldiers <- c(30.7, 60.3, 9.1)
excess_or_lack <- just_soldiers - evil_soldiers
print(excess_or_lack)
army_types <- c("Navy", "Land", "Air")
names(excess_or_lack) <- army_types
print(excess_or_lack)
total_just_soldiers <- sum(just_soldiers)
total_evil_soldiers <- sum(evil_soldiers)
total_evil_soldiers > total_just_soldiers
names(evil_soldiers) <- army_types
names(just_soldiers) <- army_types
just_navy <- just_soldiers["Navy"]
evil_navy <- evil_soldiers[c(1)]
evil_navy > just_navy
selection_army <- excess_or_lack[c(1:3)] > 0
print(selection_army)
selection_army <- excess_or_lack[c(1:3)] > 0
print(selection_army)
winning_army <- excess_or_lack[selection_army]
print(winning_army)
knitr::opts_chunk$set(echo = TRUE)
1 + 1
#Pull the trigger. So if the text any of the phrases in the string(since they have the "or" sign), they will be removed.
text <- gsub(stopwords.pattern, " ", text)
source('~/GitHub/CSX_RProject_Summer_2018/week_2/Word cloud/wordcloud.R', encoding = 'UTF-8', echo=TRUE)
source('~/GitHub/CSX_RProject_Summer_2018/week_2/Word cloud/wordcloud.R', encoding = 'UTF-8', echo=TRUE)
source('~/GitHub/CSX_RProject_Summer_2018/week_2/Word cloud/wordcloud.R', encoding = 'UTF-8', echo=TRUE)
#place all the characters we don't want into a vector
stopwords <- c("我们", "我", "的", "会", "很", "不", "这", "谁", "但是", "想","像")
source('~/GitHub/CSX_RProject_Summer_2018/week_2/Word cloud/wordcloud.R', encoding = 'UTF-8', echo=TRUE)
source('~/GitHub/CSX_RProject_Summer_2018/week_2/Word cloud/wordcloud.R', encoding = 'UTF-8', echo=TRUE)
stopwords
sessionInfo()
rm(list = ls())
#This worker initializes jiebaR workers.. what are they?
library(jiebaR)
library(wordcloud2)
library(magrittr)
wk <- worker()
#import text
text <- readLines("Mayunspeech1.txt", encoding = "UTF-8")
setwd("~/GitHub/CSX_RProject_Summer_2018/week_2/Word cloud")
#import text
text <- readLines("Mayunspeech1.txt", encoding = "UTF-8")
#place all the characters we don't want into a vector
stopwords <- c("我们", "我", "的", "会", "很", "不", "这", "谁", "但是", "想","像")
#make them into one whole string separated by '|'
stopwords.pattern <- paste0(stopwords, sep = "|", collapse = "") %>%
substr(1, nchar(.) -1)
#Pull the trigger. So if the text any of the phrases in the string(since they have the "or" sign), they will be removed.
text <- gsub(stopwords.pattern, " ", text)
#breaks apart the words.
speech <- wk[text]
#Arrange characters into table and counts into a data frame
speech <- as.data.frame(table(speech))
#Ordering the phrases in terms of frequencies in decreasing order
freq <- speech[order(speech$Freq, decreasing = T),]
#Drawing the wordcloud
wordcloud2(freq, size = 1.5, color = "random-light", backgroundColor = "grey")
source('~/GitHub/CSX_RProject_Summer_2018/week_2/Word cloud/wordcloud.R', encoding = 'UTF-8', echo=TRUE)
source('~/GitHub/CSX_RProject_Summer_2018/week_2/Word cloud/wordcloud.R', encoding = 'UTF-8', echo=TRUE)
setwd("~/GitHub/CSX_RProject_Summer_2018/week_2/Word cloud")
source('~/GitHub/CSX_RProject_Summer_2018/week_2/Word cloud/wordcloud.R', encoding = 'UTF-8', echo=TRUE)
source('~/GitHub/CSX_RProject_Summer_2018/week_2/Word cloud/wordcloud.R', encoding = 'UTF-8', echo=TRUE)
source('~/GitHub/CSX_RProject_Summer_2018/week_2/Word cloud/wordcloud.R', encoding = 'UTF-8', echo=TRUE)
rm(list = lis())
rm(list = ls())
source('~/GitHub/CSX_RProject_Summer_2018/week_2/Word cloud/wordcloud.R', encoding = 'UTF-8', echo=TRUE)
source('~/GitHub/CSX_RProject_Summer_2018/week_2/Word cloud/wordcloud.R', encoding = 'UTF-8', echo=TRUE)
source('~/GitHub/CSX_RProject_Summer_2018/week_2/Word cloud/wordcloud.R', encoding = 'UTF-8', echo=TRUE)
source('~/GitHub/CSX_RProject_Summer_2018/week_2/Word cloud/wordcloud.R', encoding = 'UTF-8', echo=TRUE)
stopwords <- c("我", "的", "在", "和", "都", "也", "不", "就", "上", "为", "我们", "这", "从","是", "会", "个","有","像","把","其实")
stopwords <- c("我", "的", "在", "和", "都", "也", "不", "就", "上", "为", "我们", "这", "从","是", "会", "个","有","像","把","其实")
source('~/GitHub/CSX_RProject_Summer_2018/week_2/Word cloud/wordcloud.R', encoding = 'UTF-8', echo=TRUE)
source('~/GitHub/CSX_RProject_Summer_2018/week_2/Word cloud/wordcloud.R', encoding = 'UTF-8', echo=TRUE)
source('~/GitHub/CSX_RProject_Summer_2018/week_2/Word cloud/wordcloud.R', encoding = 'UTF-8', echo=TRUE)
rm(list = ls())
#This worker initializes jiebaR workers.. what are they?
library(jiebaR)
library(wordcloud2)
library(magrittr)
wk <- worker()
#import text
text <- eval(parse("Mayunspeech1.txt", encoding = "UTF-8"))
#place all the characters we don't want into a vector
stopwords <- c("我","的","在","和","都","也","不","就","上","为","我们","这","从","是","会","个","有","像","把","其实")
stopwords.pattern <- paste0(stopwords, sep = "|", collapse = "") %>%
substr(1, nchar(.) -1)
#Pull the trigger. So if the text any of the phrases in the string(since they have the "or" sign), they will be removed.
text <- gsub(stopwords.pattern, " ", text)
#breaks apart the words.
speech <- wk[text]
source('~/GitHub/CSX_RProject_Summer_2018/week_2/Word cloud/wordcloud.R', encoding = 'UTF-8', echo=TRUE)
source('~/GitHub/CSX_RProject_Summer_2018/week_2/Word cloud/wordcloud.R', encoding = 'UTF-8', echo=TRUE)
source('~/GitHub/CSX_RProject_Summer_2018/week_2/Word cloud/wordcloud.R', encoding = 'UTF-8', echo=TRUE)
rm(list = ls())
#This worker initializes jiebaR workers.. what are they?
library(jiebaR)
library(wordcloud2)
library(magrittr)
wk <- worker()
#import text
text <- readLines("Mayunspeech1.txt", encoding = "UTF-8")
rm(list = ls())
#This worker initializes jiebaR workers.. what are they?
library(jiebaR)
library(wordcloud2)
library(magrittr)
wk <- worker()
#import text
text <- readLines("Mayunspeech1.txt", encoding = "UTF-8")
#place all the characters we don't want into a vector
stopwords <- c("我","的","在","和","都","也","不","就","上","为","我们","这","从","是","会","个","有","像","把","其实")
stopwords.pattern <- paste0(stopwords, sep = "|", collapse = "") %>%
substr(1, nchar(.) -1)
#Pull the trigger. So if the text any of the phrases in the string(since they have the "or" sign), they will be removed.
text <- gsub(stopwords.pattern, " ", text)
#breaks apart the words.
speech <- wk[text]
#Arrange characters into table and counts into a data frame
speech <- as.data.frame(table(speech))
#Ordering the phrases in terms of frequencies in decreasing order
freq <- speech[order(speech$Freq, decreasing = T),]
#Drawing the wordcloud
wordcloud2(freq, size = 1.5, color = "random-light", backgroundColor = "grey")
rm(list = ls())
wk <- worker()
#import text
text <- readLines("Mayunspeech1.txt", encoding = "UTF-8")
#place all the characters we don't want into a vector
stopwords <- c("我","的","在","和","都","也","不","就","上","为","我们","你们","他们","这","从","是","会","个","有","像","把","其实","了", "谁")
stopwords.pattern <- paste0(stopwords, sep = "|", collapse = "") %>%
substr(1, nchar(.) -1)
#Pull the trigger. So if the text any of the phrases in the string(since they have the "or" sign), they will be removed.
text <- gsub(stopwords.pattern, " ", text)
#breaks apart the words.
speech <- wk[text]
#Arrange characters into table and counts into a data frame
speech <- as.data.frame(table(speech))
#Ordering the phrases in terms of frequencies in decreasing order
freq <- speech[order(speech$Freq, decreasing = T),]
#Drawing the wordcloud
wordcloud2(freq, size = 1.5, color = "random-light", backgroundColor = "grey")
source('~/GitHub/CSX_RProject_Summer_2018/week_2/Word cloud/wordcloud.R', encoding = 'UTF-8', echo=TRUE)
#This worker initializes jiebaR workers.. what are they?
library(jiebaR)
library(wordcloud2)
library(magrittr)
wk <- worker()
#import text
text <- readLines("Mayunspeech1.txt", encoding = "UTF-8")
#place all the characters we don't want into a vector
stopwords <- c("我","的","在","和","都","也","不","就","上","为","我们","你们","他们","这","从","是","会","个","有","像","把","其实","了", "谁","所","但")
stopwords.pattern <- paste0(stopwords, sep = "|", collapse = "") %>%
substr(1, nchar(.) -1)
#Pull the trigger. So if the text any of the phrases in the string(since they have the "or" sign), they will be removed.
text <- gsub(stopwords.pattern, " ", text)
#breaks apart the words.
speech <- wk[text]
#Arrange characters into table and counts into a data frame
speech <- as.data.frame(table(speech))
#Ordering the phrases in terms of frequencies in decreasing order
freq <- speech[order(speech$Freq, decreasing = T),]
#Drawing the wordcloud
wordcloud2(freq, size = 1.5, color = "random-light", backgroundColor = "grey")
source('~/GitHub/CSX_RProject_Summer_2018/week_2/Word cloud/wordcloud.R', encoding = 'UTF-8', echo=TRUE)
rm(list = rs())
rm(list = ls())
wk <- worker()
#import text
text <- readLines("Mayunspeech1.txt", encoding = "UTF-8")
#breaks apart the words.
speech <- wk[text]
#Arrange characters into table and counts into a data frame
speech <- as.data.frame(table(speech))
View(speech)
#Ordering the phrases in terms of frequencies in decreasing order
freq <- speech[order(speech$Freq, decreasing = T),]
print(freq)
speech.head()
speech.heads()
speech.tails()
head(freq)
str(freq)
excesswords <-
#place all the characters we don't want into a vector
stopwords <- as.factor("我","的","在","和","都","也","不","就","上","为","我们","你们","他们","这","从","是","会","个","有","像","把","其实","了", "谁","所","但")
rm(list = ls())
#This worker initializes jiebaR workers.. what are they?
library(jiebaR)
library(wordcloud2)
library(magrittr)
Sys.setlocale("LC_ALL", locale = "Chinese")
wk <- worker()
#import text
text <- readLines("Mayunspeech1.txt", encoding = "UTF-8")
#place all the characters we don't want into a vector
stopwords <- as.factor("我","的","在","和","都","也","不","就","上","为","我们","你们","他们","这","从","是","会","个","有","像","把","其实","了", "谁","所","但")
#place all the characters we don't want into a vector
stopwords <- c("我","的","在","和","都","也","不","就","上","为","我们","你们","他们","这","从","是","会","个","有","像","把","其实","了", "谁","所","但")
stopwords.pattern <- paste0(stopwords, sep = "|", collapse = "") %>%
substr(1, nchar(.) -1)
#Pull the trigger. So if the text any of the phrases in the string(since they have the "or" sign), they will be removed.
text <- gsub(stopwords.pattern, " ", text)
#breaks apart the words.
speech <- wk[text]
#Arrange characters into table and counts into a data frame
speech <- as.data.frame(table(speech))
#Ordering the phrases in terms of frequencies in decreasing order
freq <- speech[order(speech$Freq, decreasing = T),]
str(freq)
#Drawing the wordcloud
wordcloud2(freq, size = 1.5, color = "random-light", backgroundColor = "grey")
source('~/GitHub/CSX_RProject_Summer_2018/week_2/Word cloud/wordcloud.R', encoding = 'UTF-8', echo=TRUE)
source('~/GitHub/CSX_RProject_Summer_2018/week_2/Word cloud/wordcloud.R', encoding = 'UTF-8', echo=TRUE)
source('~/GitHub/CSX_RProject_Summer_2018/week_2/Word cloud/wordcloud.R', encoding = 'UTF-8', echo=TRUE)
